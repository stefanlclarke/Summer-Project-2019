{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "representation_size = 2\n",
    "n_samples = 2000\n",
    "\n",
    "data = []\n",
    "for i in range(n_samples//2):\n",
    "    data.append([0,1])\n",
    "    data.append([1,0])\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        #generating distribution\n",
    "        self.gen1 = nn.Linear(representation_size, 10)\n",
    "        self.gen2 = nn.Linear(10, 10)\n",
    "        self.gen3 = nn.Linear(10, input_size)\n",
    "        \n",
    "        #functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def generate(self):\n",
    "        mean = torch.zeros(input_size)\n",
    "        z = torch.randn_like(mean)\n",
    "        g1 = self.relu(self.gen1(z))\n",
    "        g2 = self.relu(self.gen2(g1))\n",
    "        g3 = self.gen3(g2)\n",
    "        return g3\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        #discriminator\n",
    "        self.disc1 = nn.Linear(input_size, 10)\n",
    "        self.disc2 = nn.Linear(10, 10)\n",
    "        self.disc3 = nn.Linear(10, 1)\n",
    "        \n",
    "        #functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def discriminate(self, x):\n",
    "        d1 = self.relu(self.disc1(x))\n",
    "        d2 = self.relu(self.disc2(d1))\n",
    "        prob = self.sigmoid(self.disc3(d2))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator()\n",
    "disc = Discriminator()\n",
    "optimizer_gen = torch.optim.Adam(gen.parameters(), lr=1e-3)\n",
    "optimizer_disc = torch.optim.Adam(disc.parameters(), lr=1e-3)\n",
    "\n",
    "def lossf(Dx, Dz):\n",
    "    return -torch.sum(torch.log(Dx) + torch.log(1 - Dz))\n",
    "\n",
    "def lossgen(Z):\n",
    "    return -torch.sum(torch.log(1-Z))\n",
    "\n",
    "def train(batch_size, epochs, data):\n",
    "    for epoch in range(epochs):\n",
    "        random.shuffle(data)\n",
    "        disc_loss = 0\n",
    "        gen_loss = 0\n",
    "        for i in range(batch_size):\n",
    "            optimizer_gen.zero_grad()\n",
    "            \n",
    "            data_point = data[i]\n",
    "            generated_point = gen.generate()\n",
    "            data_point = Variable(torch.tensor(data_point).float())\n",
    "            \n",
    "            #optimize discriminator\n",
    "            optimizer_disc.zero_grad()\n",
    "            dgen = disc.discriminate(generated_point)\n",
    "            dreal = disc.discriminate(data_point)\n",
    "            \n",
    "            \n",
    "            loss = lossf(dgen, dreal)\n",
    "            loss.backward(retain_graph = True)\n",
    "            optimizer_disc.step()\n",
    "            disc_loss += loss\n",
    "            \n",
    "            #optimize generator\n",
    "            lossg = lossgen(disc.discriminate(generated_point))\n",
    "            lossg.backward()\n",
    "            optimizer_gen.step()\n",
    "            gen_loss += lossg\n",
    "        print('EPOCH {}, DISCRIMINATOR LOSS {}, GENERATOR LOSS {}'.format(epoch, disc_loss, gen_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0, DISCRIMINATOR LOSS 1284.3839111328125, GENERATOR LOSS 772.8784790039062\n",
      "EPOCH 1, DISCRIMINATOR LOSS 1223.7919921875, GENERATOR LOSS 795.8995361328125\n",
      "EPOCH 2, DISCRIMINATOR LOSS 1206.81884765625, GENERATOR LOSS 839.5524291992188\n",
      "EPOCH 3, DISCRIMINATOR LOSS 1189.7274169921875, GENERATOR LOSS 850.2138671875\n",
      "EPOCH 4, DISCRIMINATOR LOSS 1172.271240234375, GENERATOR LOSS 878.3260498046875\n"
     ]
    }
   ],
   "source": [
    "train(1000, 5, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8575], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc.discriminate(torch.tensor([0.5,0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0333, 1.0474], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
