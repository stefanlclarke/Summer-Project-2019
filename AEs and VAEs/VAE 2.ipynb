{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "input_size=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2b5d4019898>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_each_point = 700\n",
    "one_hot = []\n",
    "for i in range(num_each_point):\n",
    "    one_hot.append([1,0])\n",
    "for i in range(num_each_point):\n",
    "    one_hot.append([0,1])\n",
    "\n",
    "points = []\n",
    "for point in one_hot:\n",
    "    if point == [0,1]:\n",
    "        points.append(np.random.normal(size=1, scale=0.1))\n",
    "    if point == [1,0]:\n",
    "        points.append(np.random.normal(size=1, scale=0.1) + np.array([1]))\n",
    "points = np.array(points)\n",
    "\n",
    "one_hot_colours = []\n",
    "for i in range(len(one_hot)):\n",
    "    if one_hot[i] == [0,1]:\n",
    "        one_hot_colours.append(0)\n",
    "    else:\n",
    "        one_hot_colours.append(1)\n",
    "\n",
    "zeros = [0 for i in points]\n",
    "one_hot = np.array(one_hot)\n",
    "\n",
    "        \n",
    "plt.scatter(points[:,0],zeros, c=one_hot_colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.en1 = nn.Linear(2, 10)\n",
    "        self.en_mu = nn.Linear(10, 1)\n",
    "        self.en_std = nn.Linear(10, 1)\n",
    "        self.de1 = nn.Linear(1, 10)\n",
    "        self.de2 = nn.Linear(10, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def Z_reading(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = Variable(std.data.new(std.size()).normal_())\n",
    "        return eps.mul(std).add_(mu)\n",
    "        \n",
    "    def encrypt(self, x):\n",
    "        r1 = self.relu(self.en1(x))\n",
    "        mu = self.en_mu(r1)\n",
    "        logvar = self.en_std(r1)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def decrypt(self, z):\n",
    "        r1 = self.relu(self.de1(z))\n",
    "        r2 = self.sigmoid(self.de2(r1))\n",
    "        return r2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encrypt(x)\n",
    "        z = self.Z_reading(mu, logvar)\n",
    "        reconstruction = self.decrypt(z)\n",
    "        return reconstruction, mu, logvar\n",
    "    \n",
    "    def loss(self, reconstruction, x, mu, logvar):\n",
    "        bce = torch.nn.functional.binary_cross_entropy(reconstruction, x.view(-1, input_size))\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        # Normalise by same number of elements as in reconstruction\n",
    "        KLD /= x.view(-1, input_size).data.shape[0] * input_size\n",
    "        return bce + KLD\n",
    "    \n",
    "    def get_z(self, x):\n",
    "        mu, logvar = self.encrypt(x)\n",
    "        z = self.Z_reading(mu, std)\n",
    "        return z\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train(epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(one_hot)):\n",
    "            data = Variable(torch.from_numpy(one_hot[i]).float(), requires_grad = True)\n",
    "            optimizer.zero_grad()\n",
    "            results, mus, logvars = model(data)\n",
    "            data1 = data.clone().detach()\n",
    "            loss = model.loss(results, data1, mus, logvars)\n",
    "            loss.backward()\n",
    "        print('EPOCH: {} LOSS: {}'.format(epoch, loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stefan Clarke\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: Using a target size (torch.Size([1, 2])) that is different to the input size (torch.Size([2])) is deprecated. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0 LOSS: 0.7004820108413696\n",
      "EPOCH: 1 LOSS: 0.6636384725570679\n",
      "EPOCH: 2 LOSS: 0.655674934387207\n",
      "EPOCH: 3 LOSS: 0.7079307436943054\n",
      "EPOCH: 4 LOSS: 0.7056902647018433\n",
      "EPOCH: 5 LOSS: 0.6244689226150513\n",
      "EPOCH: 6 LOSS: 0.6777355670928955\n",
      "EPOCH: 7 LOSS: 0.7044427394866943\n",
      "EPOCH: 8 LOSS: 0.6372733116149902\n",
      "EPOCH: 9 LOSS: 0.6771923303604126\n",
      "EPOCH: 10 LOSS: 0.6732763051986694\n",
      "EPOCH: 11 LOSS: 0.6669497489929199\n",
      "EPOCH: 12 LOSS: 0.7054716944694519\n",
      "EPOCH: 13 LOSS: 0.6168605089187622\n",
      "EPOCH: 14 LOSS: 0.7021508812904358\n",
      "EPOCH: 15 LOSS: 0.6329671144485474\n",
      "EPOCH: 16 LOSS: 0.7014155387878418\n",
      "EPOCH: 17 LOSS: 0.6365833282470703\n",
      "EPOCH: 18 LOSS: 0.704717755317688\n",
      "EPOCH: 19 LOSS: 0.704393744468689\n"
     ]
    }
   ],
   "source": [
    "train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.4672, 0.4658], grad_fn=<SigmoidBackward>),\n",
       " tensor([0.3479], grad_fn=<AddBackward0>),\n",
       " tensor([-0.0571], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([1,0]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stefan Clarke\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: Using a target size (torch.Size([1, 2])) that is different to the input size (torch.Size([2])) is deprecated. Please ensure they have the same size.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4296)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss(torch.tensor([1.0, 0.0]), torch.tensor([1.0, 0.0]), torch.tensor([1.0]), torch.tensor([1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4699, 0.4652],\n",
       "         [0.4645, 0.4644],\n",
       "         [0.4325, 0.5052],\n",
       "         ...,\n",
       "         [0.4664, 0.4623],\n",
       "         [0.4281, 0.5080],\n",
       "         [0.4711, 0.4678]], grad_fn=<SigmoidBackward>), tensor([[0.3479],\n",
       "         [0.3479],\n",
       "         [0.3479],\n",
       "         ...,\n",
       "         [0.1379],\n",
       "         [0.1379],\n",
       "         [0.1379]], grad_fn=<AddmmBackward>), tensor([[-0.0571],\n",
       "         [-0.0571],\n",
       "         [-0.0571],\n",
       "         ...,\n",
       "         [-0.1214],\n",
       "         [-0.1214],\n",
       "         [-0.1214]], grad_fn=<AddmmBackward>))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Variable(torch.from_numpy(one_hot).float(), requires_grad = True)\n",
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
